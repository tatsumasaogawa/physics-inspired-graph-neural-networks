{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考: https://github.com/amazon-science/co-with-gnns-example/blob/main/gnn_example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import OrderedDict, defaultdict\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "from itertools import chain, islice, combinations\n",
    "# from networkx.algorithms.approximation.independent_set import maximum_independent_set as mis\n",
    "from networkx.algorithms.approximation import maximum_independent_set as mis\n",
    "from time import time\n",
    "\n",
    "# MacOS can have issues with MKL. For more details, see\n",
    "# https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use device: cuda, torch dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# fix seed to ensure consistent results\n",
    "seed_value = 1\n",
    "random.seed(seed_value)        # seed python RNG\n",
    "np.random.seed(seed_value)     # seed global NumPy RNG\n",
    "torch.manual_seed(seed_value)  # seed torch RNG\n",
    "\n",
    "# Set GPU/CPU\n",
    "TORCH_DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "TORCH_DTYPE = torch.float32\n",
    "print(f'Will use device: {TORCH_DEVICE}, torch dtype: {TORCH_DTYPE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import generate_graph, get_gnn, run_gnn_training, qubo_dict_to_torch, gen_combinations, loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to generate Q matrix for Maximum Independent Set problem (MIS)\n",
    "def gen_q_dict_mis(nx_G, penalty=2):\n",
    "    \"\"\"\n",
    "    Helper function to generate QUBO matrix for MIS as minimization problem.\n",
    "    \n",
    "    Input:\n",
    "        nx_G: graph as networkx graph object (assumed to be unweigthed)\n",
    "    Output:\n",
    "        Q_dic: QUBO as defaultdict\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize our Q matrix\n",
    "    Q_dic = defaultdict(int)\n",
    "\n",
    "    # Update Q matrix for every edge in the graph\n",
    "    # all off-diagonal terms get penalty\n",
    "    for (u, v) in nx_G.edges:\n",
    "        Q_dic[(u, v)] = penalty\n",
    "\n",
    "    # all diagonal terms get -1\n",
    "    for u in nx_G.nodes:\n",
    "        Q_dic[(u, u)] = -1\n",
    "\n",
    "    return Q_dic\n",
    "\n",
    "# helper function to generate Q matrix for Max Cut problem (MC)\n",
    "def gen_q_dict_mc(nx_G):\n",
    "    \"\"\"\n",
    "    Helper function to generate QUBO matrix for MC as minimization problem.\n",
    "    \n",
    "    Input:\n",
    "        nx_G: graph as networkx graph object (assumed to be unweigthed)\n",
    "    Output:\n",
    "        Q_dic: QUBO as defaultdict\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize our Q matrix\n",
    "    Q_dic = defaultdict(int)\n",
    "\n",
    "    # Update Q matrix for every edge in the graph\n",
    "    # all off-diagonal terms get penalty\n",
    "    for (u, v) in nx_G.edges:\n",
    "        Q_dic[(u, v)] = 2\n",
    "        Q_dic[(u, u)] -= 1\n",
    "        Q_dic[(v, v)] -= 1\n",
    "\n",
    "    return Q_dic\n",
    "\n",
    "def gen_adjacency_list(nx_G):\n",
    "  adjacency_list = [[] for _ in range(nx_G.number_of_nodes())]\n",
    "\n",
    "  for (u, v) in nx_G.edges:\n",
    "    adjacency_list[u].append(v)\n",
    "    adjacency_list[v].append(u)\n",
    "  \n",
    "  return adjacency_list\n",
    "\n",
    "# Run classical MIS solver (provided by NetworkX)\n",
    "def run_mis_solver(nx_graph):\n",
    "    \"\"\"\n",
    "    helper function to run traditional solver for MIS.\n",
    "    \n",
    "    Input:\n",
    "        nx_graph: networkx Graph object\n",
    "    Output:\n",
    "        ind_set_bitstring_nx: bitstring solution as list\n",
    "        ind_set_nx_size: size of independent set (int)\n",
    "        number_violations: number of violations of ind.set condition\n",
    "    \"\"\"\n",
    "    # compare with traditional solver\n",
    "    t_start = time()\n",
    "    ind_set_nx = mis(nx_graph)\n",
    "    t_solve = time() - t_start\n",
    "    ind_set_nx_size = len(ind_set_nx)\n",
    "\n",
    "    # get bitstring list\n",
    "    nx_bitstring = [1 if (node in ind_set_nx) else 0 for node in sorted(list(nx_graph.nodes))]\n",
    "    edge_set = set(list(nx_graph.edges))\n",
    "\n",
    "    # Updated to be able to handle larger scale\n",
    "    print('Calculating violations...')\n",
    "    # check for violations\n",
    "    number_violations = 0\n",
    "    for ind_set_chunk in gen_combinations(combinations(ind_set_nx, 2), 100000):\n",
    "        number_violations += len(set(ind_set_chunk).intersection(edge_set))\n",
    "\n",
    "    return nx_bitstring, ind_set_nx_size, number_violations, t_solve\n",
    "\n",
    "# Calculate results given bitstring and graph definition, includes check for violations\n",
    "def postprocess_gnn_mis(best_bitstring, nx_graph):\n",
    "    \"\"\"\n",
    "    helper function to postprocess MIS results\n",
    "\n",
    "    Input:\n",
    "        best_bitstring: bitstring as torch tensor\n",
    "    Output:\n",
    "        size_mis: Size of MIS (int)\n",
    "        ind_set: MIS (list of integers)\n",
    "        number_violations: number of violations of ind.set condition\n",
    "    \"\"\"\n",
    "\n",
    "    # get bitstring as list\n",
    "    bitstring_list = list(best_bitstring)\n",
    "\n",
    "    # compute cost\n",
    "    size_mis = sum(bitstring_list)\n",
    "\n",
    "    # get independent set\n",
    "    ind_set = set([node for node, entry in enumerate(bitstring_list) if entry == 1])\n",
    "    edge_set = set(list(nx_graph.edges))\n",
    "\n",
    "    print('Calculating violations...')\n",
    "    # check for violations\n",
    "    number_violations = 0\n",
    "    for ind_set_chunk in gen_combinations(combinations(ind_set, 2), 100000):\n",
    "        number_violations += len(set(ind_set_chunk).intersection(edge_set))\n",
    "\n",
    "    return size_mis, ind_set, number_violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating d-regular graph with n=100, d=3, seed=0\n",
      "Running GNN...\n",
      "Epoch: 0, Loss: -0.14785480499267578\n",
      "Epoch: 1000, Loss: -1.819901943206787\n",
      "Epoch: 2000, Loss: -12.973966598510742\n",
      "Epoch: 3000, Loss: -39.122989654541016\n",
      "Epoch: 4000, Loss: -67.81595611572266\n",
      "Epoch: 5000, Loss: -89.59819030761719\n",
      "Epoch: 6000, Loss: -103.88700103759766\n",
      "Epoch: 7000, Loss: -113.13985443115234\n",
      "Epoch: 8000, Loss: -119.13922119140625\n",
      "Epoch: 9000, Loss: -122.97570037841797\n",
      "Epoch: 10000, Loss: -125.3886947631836\n",
      "Epoch: 11000, Loss: -126.84629821777344\n",
      "Epoch: 12000, Loss: -127.71759033203125\n",
      "Epoch: 13000, Loss: -128.23631286621094\n",
      "Epoch: 14000, Loss: -128.54486083984375\n",
      "Epoch: 15000, Loss: -128.72906494140625\n",
      "Epoch: 16000, Loss: -128.83843994140625\n",
      "Epoch: 17000, Loss: -128.903564453125\n",
      "Stopping early on epoch 17050 (patience: 1000)\n",
      "GNN training (n=100) took 89.751\n",
      "GNN final continuous loss: -128.90602111816406\n",
      "GNN best continuous loss: -128.90602111816406\n",
      "Max cut size found by GNN is 129.0\n",
      "Took 90.8s, model training took 90.793s\n"
     ]
    }
   ],
   "source": [
    "for n in range(100, 101):\n",
    "  for seed_value in range(1):\n",
    "    # Step 1 - Set hyperparameters\n",
    "    # Graph hypers\n",
    "    # n = 100\n",
    "    d = 3\n",
    "    p = 0.1\n",
    "    graph_type = 'reg'\n",
    "\n",
    "    # NN learning hypers #\n",
    "    number_epochs = int(1e5)\n",
    "    learning_rate = 1e-4\n",
    "    PROB_THRESHOLD = 0.5\n",
    "\n",
    "    # Early stopping to allow NN to train to near-completion\n",
    "    tol = 1e-4          # loss must change by more than tol, or trigger\n",
    "    patience = 1000    # number early stopping triggers before breaking loop\n",
    "\n",
    "    # Problem size (e.g. graph size)\n",
    "    # n = 100\n",
    "\n",
    "    # Establish dim_embedding and hidden_dim values\n",
    "    dim_embedding = int(np.cbrt(n))    # e.g. 10\n",
    "    hidden_dim = int(dim_embedding/2)  # e.g. 5\n",
    "\n",
    "    # Step 2 - Generate random graph\n",
    "    # Constructs a random d-regular or p-probabilistic graph\n",
    "    nx_graph = generate_graph(n=n, d=d, p=p, graph_type=graph_type, random_seed=seed_value)\n",
    "    # get DGL graph from networkx graph, load onto device\n",
    "    graph_dgl = dgl.from_networkx(nx_graph=nx_graph)\n",
    "    graph_dgl = graph_dgl.to(TORCH_DEVICE)\n",
    "\n",
    "    # Construct Q matrix for graph\n",
    "    q_torch = qubo_dict_to_torch(nx_graph, gen_q_dict_mc(nx_graph), torch_dtype=TORCH_DTYPE, torch_device=TORCH_DEVICE)\n",
    "\n",
    "\n",
    "    # Step 3 - Set up optimizer/GNN architecture\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 1,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience\n",
    "    }\n",
    "\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "\n",
    "    # For tracking hyperparameters in results object\n",
    "    gnn_hypers.update(opt_params)\n",
    "\n",
    "\n",
    "    # Step 4 - Run GNN training\n",
    "    print('Running GNN...')\n",
    "    gnn_start = time()\n",
    "\n",
    "    _, epoch, final_bitstring, best_bitstring = run_gnn_training(\n",
    "        q_torch, graph_dgl, net, embed, optimizer, gnn_hypers['number_epochs'],\n",
    "        gnn_hypers['tolerance'], gnn_hypers['patience'], gnn_hypers['prob_threshold'], n, d, seed_value)\n",
    "\n",
    "    gnn_time = time() - gnn_start\n",
    "\n",
    "\n",
    "    # Step 5 - Post-process GNN results\n",
    "    final_loss = loss_func(final_bitstring.float(), q_torch)\n",
    "    final_bitstring_str = ','.join([str(x) for x in final_bitstring])\n",
    "\n",
    "    # Process bitstring reported by GNN\n",
    "    # size_mis, ind_set, number_violations = postprocess_gnn_mis(best_bitstring, nx_graph)\n",
    "    gnn_tot_time = time() - gnn_start\n",
    "\n",
    "    # print(f'Independence number found by GNN is {size_mis} with {number_violations} violations')\n",
    "    print(f'Max cut size found by GNN is {-final_loss}')\n",
    "    print(f'Took {round(gnn_tot_time, 3)}s, model training took {round(gnn_time, 3)}s')\n",
    "\n",
    "    outfile = open('data/2gnn_n' + str(n) + '_d' + str(d) + '_seed' + str(seed_value) + '.dat', 'w')\n",
    "    outfile.write('# 01: mc_size 02: time 03: total time 04: epoch\\n')\n",
    "    outfile.write(str(-final_loss.item()) + ' ' + str(gnn_time) + ' ' + str(gnn_tot_time) + ' ' + str(epoch) + '\\n')\n",
    "    outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sotsuron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d723d482f44550deffb80785d9c00aed6907ee3fec4dcbfe70e7bc0ec3c6a0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
